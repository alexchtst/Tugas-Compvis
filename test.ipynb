{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b0a0aa",
   "metadata": {},
   "source": [
    "## GRAY IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aefeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anot_path = \"./data/attention.csv\"\n",
    "images_path = \"./data/datasets/\"\n",
    "\n",
    "gray_images_path = \"./data/grayimage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e22543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(anot_path)\n",
    "df.columns = ['filename', 'score']\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/gray_data.csv\"\n",
    "\n",
    "data = {\n",
    "    'width': [],\n",
    "    'height': [],\n",
    "    'file_path': [],\n",
    "    'score': []\n",
    "}\n",
    "\n",
    "if not os.path.exists(gray_images_path):\n",
    "    os.makedirs(gray_images_path)\n",
    "\n",
    "for item, score in zip(df['filename'].tolist(), df['score'].tolist()):\n",
    "    file_path = os.path.join(images_path, item)\n",
    "    gray_path = os.path.join(gray_images_path, item)\n",
    "\n",
    "    img = Image.open(file_path).convert(\"L\")\n",
    "    \n",
    "    img.save(gray_path)\n",
    "    \n",
    "    data['width'].append(img.size[0])\n",
    "    data['height'].append(img.size[1])\n",
    "    data['file_path'].append(gray_path)\n",
    "    data['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ebb89",
   "metadata": {},
   "source": [
    "## BLUR CANNY CONTOUR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9a18598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# anomali data 69, 5, 36\n",
    "# rd_idx = 5\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def Proccess(df = df, idx = None, biar_rapih = False):\n",
    "    if idx == None:\n",
    "        idx = random.randint(0, len(df['file_path'].tolist()))\n",
    "    \n",
    "    sample_image_name = df['file_path'].tolist()[idx]\n",
    "    score = df['score'].tolist()[idx]\n",
    "\n",
    "    img_np = np.array(Image.open(sample_image_name))\n",
    "    \n",
    "    if not biar_rapih:\n",
    "        # gausah didebug ini [biar apa biarin | pusing gw njir ngeliatnya]\n",
    "        print(f\"image idx: {idx} | score: {score} | filename: {sample_image_name}\")\n",
    "        print(f\"image size: {img_np.shape}\")\n",
    "\n",
    "    blank = np.zeros(shape=img_np.shape, dtype='uint8')\n",
    "\n",
    "    gaussBlur = cv.GaussianBlur(img_np, (175, 175), 0.3)\n",
    "    canny = cv.Canny(gaussBlur, 100, 100)\n",
    "\n",
    "    _, tresh = cv.threshold(img_np, 125, 255, cv.THRESH_BINARY)\n",
    "    _, blurtresh = cv.threshold(gaussBlur, 125, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cv.drawContours(blank, contours, -1, 255, 1)\n",
    "    \n",
    "    images = [img_np, gaussBlur, canny, tresh, blank]\n",
    "    titles = ['Gray', 'Gaussian Blur', 'Canny', 'Threshold', 'Contours Drawn']\n",
    "    \n",
    "    return images, titles\n",
    "\n",
    "def ShowImage(images, titles):\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 3, i + 1)  # 2 baris, 3 kolom\n",
    "        if len(images[i].shape) == 2:  # grayscale\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "        else:  # RGB image\n",
    "            plt.imshow(cv.cvtColor(images[i], cv.COLOR_BGR2RGB))\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b76b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max-width: 1080 | min-width: 102 | max-height: 550 | min-height: 50\n"
     ]
    }
   ],
   "source": [
    "max_w = max(df['width'].tolist())\n",
    "min_w = min(df['width'].tolist())\n",
    "\n",
    "max_h = max(df['height'].tolist())\n",
    "min_h = min(df['height'].tolist())\n",
    "\n",
    "print(f\"max-width: {max_w} | min-width: {min_w} | max-height: {max_h} | min-height: {min_h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4942ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    images, titles = Proccess()\n",
    "    ShowImage(images, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a8ebb",
   "metadata": {},
   "source": [
    "## LOAD DATA INTO NDARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6359323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>619.033445</td>\n",
       "      <td>204.919732</td>\n",
       "      <td>2.535117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>217.750917</td>\n",
       "      <td>103.918529</td>\n",
       "      <td>1.400361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>632.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>785.000000</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1080.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             width      height       score\n",
       "count   299.000000  299.000000  299.000000\n",
       "mean    619.033445  204.919732    2.535117\n",
       "std     217.750917  103.918529    1.400361\n",
       "min     102.000000   50.000000    0.000000\n",
       "25%     460.000000  126.000000    1.000000\n",
       "50%     632.000000  194.000000    3.000000\n",
       "75%     785.000000  254.500000    4.000000\n",
       "max    1080.000000  550.000000    4.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# mean width = 624\n",
    "# mean height = 208\n",
    "\n",
    "# biar 2^ pake width = 512 (2**9)\n",
    "# biar 2^ pake height = 256 (2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7470714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(np_img, w = 512, h = 256):\n",
    "    return cv.resize(np_img, dsize=(w, h), interpolation=cv.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4826ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_np = [] # gray images\n",
    "gaussBlur_np = []\n",
    "canny_np = []\n",
    "tresh_np = []\n",
    "contour_np = []\n",
    "\n",
    "# load to array\n",
    "for i in range(len(df['file_path'].tolist())):\n",
    "    '''\n",
    "    images = [\n",
    "        img_np, gaussBlur, canny, tresh, blank]\n",
    "        [gray, gaussblur(gray), canny(gray), tresh(gray), contour(grey)\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    images, _ = Proccess(idx=i, biar_rapih=True)\n",
    "    # print(type(resize(images[0])))\n",
    "    # print(resize(images[0]))\n",
    "    # print(resize(images[0]).shape)\n",
    "    # break\n",
    "    gray_np.append(resize(images[0]))\n",
    "    gaussBlur_np.append(resize(images[1]))\n",
    "    canny_np.append(resize(images[2]))\n",
    "    tresh_np.append(resize(images[3]))\n",
    "    contour_np.append(resize(images[4]))\n",
    "\n",
    "# transform into \n",
    "gray_np = np.array(gray_np)\n",
    "gaussBlur_np = np.array(gaussBlur_np)\n",
    "canny_np = np.array(canny_np)\n",
    "tresh_np = np.array(tresh_np)\n",
    "contour_np = np.array(contour_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb6a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 256, 512) (299, 256, 512) (299, 256, 512) (299, 256, 512) (299, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "print(gray_np.shape, gaussBlur_np.shape, canny_np.shape, tresh_np.shape, contour_np.shape)\n",
    "\n",
    "# pake dah mau pake yang mana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd399f",
   "metadata": {},
   "source": [
    "## TRY MODEL [alex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d9ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053be906",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "be614348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "216b6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=5):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3, stride=1, padding=1)  # (8, 512, 256)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # (8, 256, 128)\n",
    "\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)  # (16, 256, 128)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((8,8))\n",
    "        self.flatten_dim = 1024\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Tambahkan dropout\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _initialize_fc1(self, input_channels):\n",
    "        dummy_input = torch.zeros(1, input_channels, 512, 256)\n",
    "        x = F.relu(self.conv1(dummy_input))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        flatten_dim = x.view(1,-1).shape[1]\n",
    "        self.fc1 = nn.Linear(flatten_dim, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) #torch.Size([1, 8, 512, 256])\n",
    "        # print(x.shape)\n",
    "        x = self.pool(x) #torch.Size([1, 8, 256, 128])\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv2(x)) #torch.Size([1, 16, 256, 128])\n",
    "        # print(x.shape)\n",
    "        x = self.adaptive_pool(x)#torch.Size([1, 16, 8, 8])\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)  # Flatten #torch.Size([1, 1024])\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(x)  # Terapkan dropout hanya saat training\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cd78e530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "y_one_hot_encode = []\n",
    "for i in df['score'].tolist():\n",
    "    onehot_temp = [0]*5\n",
    "    onehot_temp[i] = 1\n",
    "    y_one_hot_encode.append(onehot_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1bcf95ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([239, 1, 512, 256]) torch.Size([239])\n",
      "torch.Size([60, 1, 512, 256]) torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "X = tresh_np.reshape(-1, 1, 512, 256).astype(np.float32)\n",
    "X = X / 255.0\n",
    "y = np.array(y_one_hot_encode).astype(np.float32)\n",
    "\n",
    "# convert data to tensor\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y, dtype=torch.float64)\n",
    "\n",
    "# Split sebelum konversi ke tensor\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_int, test_size=0.2, random_state=42)\n",
    "\n",
    "# Konversi ke tensor\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Cek shape\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "88f6ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 2, 0, 0, 1, 4, 1, 1, 3, 3, 0, 4, 4, 1, 4, 4, 2, 3, 0, 4, 0, 3, 2,\n",
      "        0, 2, 2, 4, 1, 4, 1, 1, 4, 4, 3, 1, 2, 4, 1, 2, 2, 0, 1, 4, 2, 4, 0, 4,\n",
      "        4, 1, 3, 2, 0, 4, 2, 1, 3, 3, 4, 1, 3, 3, 1, 0, 1, 1, 1, 3, 2, 4, 2, 4,\n",
      "        2, 1, 4, 3, 2, 4, 4, 4, 1, 2, 2, 2, 4, 4, 2, 2, 4, 4, 1, 4, 4, 4, 2, 3,\n",
      "        4, 4, 3, 4, 2, 4, 4, 1, 4, 4, 1, 1, 4, 4, 1, 4, 3, 4, 1, 1, 4, 2, 4, 2,\n",
      "        2, 4, 1, 0, 4, 2, 1, 3, 0, 1, 4, 2, 2, 1, 4, 2, 1, 3, 3, 1, 4, 3, 4, 2,\n",
      "        4, 4, 4, 4, 2, 4, 4, 1, 0, 3, 3, 4, 4, 1, 1, 4, 3, 3, 4, 0, 4, 2, 2, 4,\n",
      "        4, 4, 3, 1, 3, 4, 3, 3, 4, 3, 4, 1, 2, 3, 4, 3, 3, 4, 4, 1, 4, 2, 4, 1,\n",
      "        1, 4, 2, 0, 2, 3, 4, 4, 2, 4, 1, 3, 4, 0, 4, 4, 2, 3, 1, 4, 4, 1, 1, 2,\n",
      "        4, 1, 2, 0, 0, 4, 2, 0, 4, 1, 4, 1, 4, 4, 4, 1, 0, 0, 4, 2, 4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "sample_input = X_train[0].unsqueeze(0)\n",
    "\n",
    "model(sample_input)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a89724be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(X_train, y_train)\n",
    "trainloader = DataLoader(dataset, batch_size=12, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "testloader = DataLoader(test_dataset, batch_size=12, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "385ebd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "575b02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a912a045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights : tensor([2.0621, 1.0873, 1.0873, 1.2723, 0.5292], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "labels = df['score'].values\n",
    "\n",
    "class_labels = np.unique(labels)\n",
    "\n",
    "weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=labels)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Class Weights : {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4a6738b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameter\n",
    "epochs = 10   # Coba dengan lebih banyak epoch untuk melihat apakah model dapat lebih baik\n",
    "learning_rate = 0.001  # Turunkan learning rate untuk memperbaiki konvergensi\n",
    "batch_size = 64\n",
    "\n",
    "model = CNN().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "508fc840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 33.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.5641\n",
      "Validation Loss: 1.5787\n",
      "Model improved. Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 66.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 1.5071\n",
      "Validation Loss: 1.5856\n",
      "No improvement. EarlyStopping counter: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 67.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 1.5083\n",
      "Validation Loss: 1.5698\n",
      "Model improved. Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 67.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 1.5180\n",
      "Validation Loss: 1.5712\n",
      "No improvement. EarlyStopping counter: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 67.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 1.5032\n",
      "Validation Loss: 1.6069\n",
      "No improvement. EarlyStopping counter: 2/2\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "patience = 2\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_res = model(data)\n",
    "        loss = criterion(pred_res, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # ===== VALIDASI =====\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_target in testloader:\n",
    "            val_data = val_data.to(device)\n",
    "            val_target = val_target.to(device)\n",
    "            val_output = model(val_data)\n",
    "            v_loss = criterion(val_output, val_target)\n",
    "            val_loss += v_loss.item()\n",
    "    val_loss /= len(testloader)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # ===== EARLY STOPPING =====\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')  # simpan model terbaik\n",
    "        print(\"Model improved. Saving model.\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement. EarlyStopping counter: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "633ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/model-again.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dca10eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "trainloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('model/model1.pth'))\n",
    "loaded_model.to(device)\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2ea93a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 256])\n",
      "tensor([[ 0.0046,  0.0285, -0.0270, -0.0891,  0.0051]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "rd_idx = random.randint(0, 198)\n",
    "\n",
    "sample_input = X_train[rd_idx].unsqueeze(0).to(device)\n",
    "sample_output = y_train[rd_idx]\n",
    "print(sample_input.shape)\n",
    "\n",
    "pred_result = loaded_model(sample_input)\n",
    "print(pred_result, sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b771b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acc(loader, model, device):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.eval()  # Set model ke mode evaluasi\n",
    "    with torch.no_grad():  # Tidak perlu track gradient\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores = model(x)  # forward\n",
    "            _, preds = scores.max(1)  # ambil index prediksi tertinggi\n",
    "\n",
    "            num_correct += (preds == y).sum().item()  # kalau target one-hot\n",
    "            num_samples += y.size(0)\n",
    "\n",
    "    acc = num_correct / num_samples\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    model.train()  # Kembalikan ke mode training setelah evaluasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "358102ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.33%\n"
     ]
    }
   ],
   "source": [
    "check_acc(testloader, loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_acc(trainloader, loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_acc(trainloader, loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dcc37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
