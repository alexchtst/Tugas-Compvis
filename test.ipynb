{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b0a0aa",
   "metadata": {},
   "source": [
    "## GRAY IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aefeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anot_path = \"./data/attention.csv\"\n",
    "images_path = \"./data/datasets/\"\n",
    "\n",
    "gray_images_path = \"./data/grayimage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e22543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(anot_path)\n",
    "df.columns = ['filename', 'score']\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/gray_data.csv\"\n",
    "\n",
    "data = {\n",
    "    'width': [],\n",
    "    'height': [],\n",
    "    'file_path': [],\n",
    "    'score': []\n",
    "}\n",
    "\n",
    "if not os.path.exists(gray_images_path):\n",
    "    os.makedirs(gray_images_path)\n",
    "\n",
    "for item, score in zip(df['filename'].tolist(), df['score'].tolist()):\n",
    "    file_path = os.path.join(images_path, item)\n",
    "    gray_path = os.path.join(gray_images_path, item)\n",
    "\n",
    "    img = Image.open(file_path).convert(\"L\")\n",
    "    \n",
    "    img.save(gray_path)\n",
    "    \n",
    "    data['width'].append(img.size[0])\n",
    "    data['height'].append(img.size[1])\n",
    "    data['file_path'].append(gray_path)\n",
    "    data['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ebb89",
   "metadata": {},
   "source": [
    "## BLUR CANNY CONTOUR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a18598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# anomali data 69, 5, 36\n",
    "# rd_idx = 5\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def Proccess(df = df, idx = None, biar_rapih = False):\n",
    "    if idx == None:\n",
    "        idx = random.randint(0, len(df['file_path'].tolist()))\n",
    "    \n",
    "    sample_image_name = df['file_path'].tolist()[idx]\n",
    "    score = df['score'].tolist()[idx]\n",
    "\n",
    "    img_np = np.array(Image.open(sample_image_name))\n",
    "    \n",
    "    if not biar_rapih:\n",
    "        # gausah didebug ini [biar apa biarin | pusing gw njir ngeliatnya]\n",
    "        print(f\"image idx: {idx} | score: {score} | filename: {sample_image_name}\")\n",
    "        print(f\"image size: {img_np.shape}\")\n",
    "\n",
    "    blank = np.zeros(shape=img_np.shape, dtype='uint8')\n",
    "\n",
    "    gaussBlur = cv.GaussianBlur(img_np, (175, 175), 0.3)\n",
    "    canny = cv.Canny(gaussBlur, 100, 100)\n",
    "\n",
    "    _, tresh = cv.threshold(img_np, 125, 255, cv.THRESH_BINARY)\n",
    "    _, blurtresh = cv.threshold(gaussBlur, 125, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cv.drawContours(blank, contours, -1, 255, 1)\n",
    "    \n",
    "    images = [img_np, gaussBlur, canny, tresh, blank]\n",
    "    titles = ['Gray', 'Gaussian Blur', 'Canny', 'Threshold', 'Contours Drawn']\n",
    "    \n",
    "    return images, titles\n",
    "\n",
    "def ShowImage(images, titles):\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 3, i + 1)  # 2 baris, 3 kolom\n",
    "        if len(images[i].shape) == 2:  # grayscale\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "        else:  # RGB image\n",
    "            plt.imshow(cv.cvtColor(images[i], cv.COLOR_BGR2RGB))\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b76b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = max(df['width'].tolist())\n",
    "min_w = min(df['width'].tolist())\n",
    "\n",
    "max_h = max(df['height'].tolist())\n",
    "min_h = min(df['height'].tolist())\n",
    "\n",
    "print(f\"max-width: {max_w} | min-width: {min_w} | max-height: {max_h} | min-height: {min_h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    images, titles = Proccess()\n",
    "    ShowImage(images, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a8ebb",
   "metadata": {},
   "source": [
    "## LOAD DATA INTO NDARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# mean width = 624\n",
    "# mean height = 208\n",
    "\n",
    "# biar 2^ pake width = 512 (2**9)\n",
    "# biar 2^ pake height = 256 (2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7470714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(np_img, w = 512, h = 256):\n",
    "    return cv.resize(np_img, dsize=(w, h), interpolation=cv.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_np = [] # gray images\n",
    "gaussBlur_np = []\n",
    "canny_np = []\n",
    "tresh_np = []\n",
    "contour_np = []\n",
    "\n",
    "# load to array\n",
    "for i in range(len(df['file_path'].tolist())):\n",
    "    '''\n",
    "    images = [\n",
    "        img_np, gaussBlur, canny, tresh, blank]\n",
    "        [gray, gaussblur(gray), canny(gray), tresh(gray), contour(grey)\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    images, _ = Proccess(idx=i, biar_rapih=True)\n",
    "    # print(type(resize(images[0])))\n",
    "    # print(resize(images[0]))\n",
    "    # print(resize(images[0]).shape)\n",
    "    # break\n",
    "    gray_np.append(resize(images[0]))\n",
    "    gaussBlur_np.append(resize(images[1]))\n",
    "    canny_np.append(resize(images[2]))\n",
    "    tresh_np.append(resize(images[3]))\n",
    "    contour_np.append(resize(images[4]))\n",
    "\n",
    "# transform into \n",
    "gray_np = np.array(gray_np)\n",
    "gaussBlur_np = np.array(gaussBlur_np)\n",
    "canny_np = np.array(canny_np)\n",
    "tresh_np = np.array(tresh_np)\n",
    "contour_np = np.array(contour_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gray_np.shape, gaussBlur_np.shape, canny_np.shape, tresh_np.shape, contour_np.shape)\n",
    "\n",
    "# pake dah mau pake yang mana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd399f",
   "metadata": {},
   "source": [
    "## TRY MODEL [alex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76ef3a",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tresh_np.reshape(tresh_np.shape[0], -1)\n",
    "X = X / 255\n",
    "y = np.array(df['score']).reshape(-1, 1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0905537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train[0]), X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d71ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train[0]), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 8, 16, 64],\n",
    "    'min_samples_split': [5, 10, 15],\n",
    "    'min_samples_leaf': [5, 15, 20],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7903817",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=random_forest,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb966788",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_\n",
    "best_estimators = random_search.best_estimator_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"best scores: {best_score} \\nbest parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053be906",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be614348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels = 1, num_classes = 6):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # input 1 => output 8 => output size = torch.Size([8, 512, 256])\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # max pool => output size = torch.Size([8, 511, 255]) \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        \n",
    "        # input 8 => output size = torch.Size([16, 511, 255])\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # fully connected layer => output size = torch.Size([6])\n",
    "        self.fc1 = nn.Linear(2084880, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_result1 = self.conv1(x)\n",
    "        pool_result = self.pool(conv_result1)\n",
    "        conv_result2 = self.conv2(pool_result)\n",
    "        flatten_result = torch.flatten(conv_result2, start_dim=1)\n",
    "        fully_connected = self.fc1(flatten_result)\n",
    "        \n",
    "        return fully_connected    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "y_one_hot_encode = []\n",
    "for i in df['score'].tolist():\n",
    "    onehot_temp = [0]*6\n",
    "    onehot_temp[i] = 1\n",
    "    y_one_hot_encode.append(onehot_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tresh_np.reshape(-1, 1, 512, 256).astype(np.float32)\n",
    "X = X / 255.0\n",
    "y = np.array(y_one_hot_encode).astype(np.float32)\n",
    "\n",
    "# convert data to tensor\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee81602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN()\n",
    "\n",
    "# sample_input = X[0].unsqueeze(0)\n",
    "\n",
    "# conv1res = model.conv1(sample_input)\n",
    "# poolres = model.pool(conv1res)\n",
    "# conv2res = model.conv2(poolres)\n",
    "# flattenres = torch.flatten(conv2res, start_dim=1)\n",
    "# fcres = model.fc1(flattenres)\n",
    "\n",
    "# print(sample_input.shape, conv1res.shape, poolres.shape, conv2res.shape, flattenres.shape, fcres.shape, model(sample_input).shape)\n",
    "# print(fcres, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ebd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(y[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "trainloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6738b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.025\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # predict | forward\n",
    "        pred_res = model(data)\n",
    "        loss = criterion(pred_res, target)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "                \n",
    "        # bacward | calculate gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    print(f\"epoch: {epoch} / {epochs}\")\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    print(f\"Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca10eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = TensorDataset(X, y)\n",
    "trainloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "loaded_model = CNN()\n",
    "loaded_model.load_state_dict(torch.load('model/model1.pth'))\n",
    "loaded_model.to(device)\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea93a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_idx = random.randint(0, 198)\n",
    "\n",
    "sample_input = X[rd_idx].unsqueeze(0)\n",
    "sample_output = y[rd_idx]\n",
    "print(sample_input.shape)\n",
    "\n",
    "pred_result = loaded_model(sample_input)\n",
    "print(pred_result, sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_acc(loader, model, device):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.eval()  # Set model ke mode evaluasi\n",
    "    with torch.no_grad():  # Tidak perlu track gradient\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            scores = model(x)  # forward\n",
    "            _, preds = scores.max(1)  # ambil index prediksi tertinggi\n",
    "\n",
    "            num_correct += (preds == y.argmax(dim=1)).sum().item()  # kalau target one-hot\n",
    "            num_samples += y.size(0)\n",
    "\n",
    "    acc = num_correct / num_samples\n",
    "    print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    model.train()  # Kembalikan ke mode training setelah evaluasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358102ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_acc(trainloader, loaded_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cc1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
