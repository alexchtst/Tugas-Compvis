{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b0a0aa",
   "metadata": {},
   "source": [
    "## GRAY IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aefeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "anot_path = \"./data/attention.csv\"\n",
    "images_path = \"./data/datasets/\"\n",
    "\n",
    "gray_images_path = \"./data/grayimage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e22543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(anot_path)\n",
    "df.columns = ['filename', 'score']\n",
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/gray_data.csv\"\n",
    "\n",
    "data = {\n",
    "    'width': [],\n",
    "    'height': [],\n",
    "    'file_path': [],\n",
    "    'score': []\n",
    "}\n",
    "\n",
    "if not os.path.exists(gray_images_path):\n",
    "    os.makedirs(gray_images_path)\n",
    "\n",
    "for item, score in zip(df['filename'].tolist(), df['score'].tolist()):\n",
    "    file_path = os.path.join(images_path, item)\n",
    "    gray_path = os.path.join(gray_images_path, item)\n",
    "\n",
    "    img = Image.open(file_path).convert(\"L\")\n",
    "    \n",
    "    img.save(gray_path)\n",
    "    \n",
    "    data['width'].append(img.size[0])\n",
    "    data['height'].append(img.size[1])\n",
    "    data['file_path'].append(gray_path)\n",
    "    data['score'].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ebb89",
   "metadata": {},
   "source": [
    "## BLUR CANNY CONTOUR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a18598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# anomali data 69, 5, 36\n",
    "# rd_idx = 5\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def Proccess(df = df, idx = None, biar_rapih = False):\n",
    "    if idx == None:\n",
    "        idx = random.randint(0, len(df['file_path'].tolist()))\n",
    "    \n",
    "    sample_image_name = df['file_path'].tolist()[idx]\n",
    "    score = df['score'].tolist()[idx]\n",
    "\n",
    "    img_np = np.array(Image.open(sample_image_name))\n",
    "    \n",
    "    if not biar_rapih:\n",
    "        # gausah didebug ini [biar apa biarin | pusing gw njir ngeliatnya]\n",
    "        print(f\"image idx: {idx} | score: {score} | filename: {sample_image_name}\")\n",
    "        print(f\"image size: {img_np.shape}\")\n",
    "\n",
    "    blank = np.zeros(shape=img_np.shape, dtype='uint8')\n",
    "\n",
    "    gaussBlur = cv.GaussianBlur(img_np, (175, 175), 0.3)\n",
    "    canny = cv.Canny(gaussBlur, 100, 100)\n",
    "\n",
    "    _, tresh = cv.threshold(img_np, 125, 255, cv.THRESH_BINARY)\n",
    "    _, blurtresh = cv.threshold(gaussBlur, 125, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cv.drawContours(blank, contours, -1, 255, 1)\n",
    "    \n",
    "    images = [img_np, gaussBlur, canny, tresh, blank]\n",
    "    titles = ['Gray', 'Gaussian Blur', 'Canny', 'Threshold', 'Contours Drawn']\n",
    "    \n",
    "    return images, titles\n",
    "\n",
    "def ShowImage(images, titles):\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 3, i + 1)  # 2 baris, 3 kolom\n",
    "        if len(images[i].shape) == 2:  # grayscale\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "        else:  # RGB image\n",
    "            plt.imshow(cv.cvtColor(images[i], cv.COLOR_BGR2RGB))\n",
    "        plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b76b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = max(df['width'].tolist())\n",
    "min_w = min(df['width'].tolist())\n",
    "\n",
    "max_h = max(df['height'].tolist())\n",
    "min_h = min(df['height'].tolist())\n",
    "\n",
    "print(f\"max-width: {max_w} | min-width: {min_w} | max-height: {max_h} | min-height: {min_h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    images, titles = Proccess()\n",
    "    ShowImage(images, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a8ebb",
   "metadata": {},
   "source": [
    "## LOAD DATA INTO NDARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "file_path = \"data/gray_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7470714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(np_img, w = 512, h = 256):\n",
    "    return cv.resize(np_img, dsize=(w, h), interpolation=cv.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_np = [] # gray images\n",
    "gaussBlur_np = []\n",
    "canny_np = []\n",
    "tresh_np = []\n",
    "contour_np = []\n",
    "\n",
    "# load to array\n",
    "for i in range(len(df['file_path'].tolist())):\n",
    "    '''\n",
    "    images = [\n",
    "        img_np, gaussBlur, canny, tresh, blank]\n",
    "        [gray, gaussblur(gray), canny(gray), tresh(gray), contour(grey)\n",
    "    ]\n",
    "    '''\n",
    "    \n",
    "    images, _ = Proccess(idx=i, biar_rapih=True)\n",
    "    # print(type(resize(images[0])))\n",
    "    # print(resize(images[0]))\n",
    "    # print(resize(images[0]).shape)\n",
    "    # break\n",
    "    gray_np.append(resize(images[0]))\n",
    "    gaussBlur_np.append(resize(images[1]))\n",
    "    canny_np.append(resize(images[2]))\n",
    "    tresh_np.append(resize(images[3]))\n",
    "    contour_np.append(resize(images[4]))\n",
    "\n",
    "# transform into \n",
    "gray_np = np.array(gray_np)\n",
    "gaussBlur_np = np.array(gaussBlur_np)\n",
    "canny_np = np.array(canny_np)\n",
    "tresh_np = np.array(tresh_np)\n",
    "contour_np = np.array(contour_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gray_np.shape, gaussBlur_np.shape, canny_np.shape, tresh_np.shape, contour_np.shape)\n",
    "\n",
    "# pake dah mau pake yang mana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gray_np.reshape(gray_np.shape[0], -1)\n",
    "X = X / 255\n",
    "y = np.array(df['score']).reshape(-1, 1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27077aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0905537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train[0]), X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d71ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train[0]), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e959d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2813ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gray_np.reshape(-1, 1, 512, 256).astype(np.float32)\n",
    "X = X / 255.0\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "# convert data to tensor\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ebd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(y[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "trainloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e092d",
   "metadata": {},
   "source": [
    "## EFFICIENT NET B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b706c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b7()\n",
    "\n",
    "conv1_weight = model.features[0][0].weight.data\n",
    "new_conv1_weight = conv1_weight.mean(dim=1, keepdim=True)\n",
    "\n",
    "model.features[0][0] = torch.nn.Conv2d(3, 32, kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=False)\n",
    "model.features[0][0].weight.data = new_conv1_weight\n",
    "\n",
    "x = torch.randn(1,1, 512,256)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 5)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed962e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=True),\n",
    "    nn.Linear(model.classifier[1].in_features, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a674ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb988e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'EfficientNet_B7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94fb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "    print(f\"Batch {batch_idx+1}\")\n",
    "    print(f\"Inputs Shape : {inputs.shape}, Targets Shape : {targets.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ec92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "for input, target in train_loader:\n",
    "    print(input.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724aebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for inputs, targets, in train_loader:\n",
    "        inputs,targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs,targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == targets).sum().item()\n",
    "        total_preds += targets.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct_preds / total_preds\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss : {epoch_loss:.4f}, Accuracy : {epoch_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa961e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Akurasi pada data test : {accuracy:.3f}%\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790761ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wrong = 0\n",
    "for inputs, labels in test_loader:\n",
    "    outputs = model(inputs.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] != labels[i]:\n",
    "            plt.imshow(inputs[i].squeeze(), cmap=\"gray\")\n",
    "            plt.title(f\"True: {labels[i]}, Pred: {preds[i]}\")\n",
    "            plt.show()\n",
    "            wrong += 1\n",
    "        if wrong > 5:\n",
    "            break\n",
    "    if wrong > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc01191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
